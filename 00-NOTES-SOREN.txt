XXXXXXXXXXXXXX
==========================================================================



XXXXXXXXXXXXXX
==========================================================================



XXXXXXXXXXXXXX
==========================================================================



Nervana Wants to Make Special Hardware Just for Deep Learning  - April 17, 2014
==========================================================================
Interesting.... (epiphany?)

http://recode.net/2014/04/17/nervana-wants-to-make-special-hardware-just-for-deep-learning/

Deep learning, the current belle of the artificial-intelligence ball, has helped products like speech recognition and image search, from companies like Google, Microsoft and Facebook, make great leaps forward in recent years. It’s an older technique that was enlivened by massive quantities of data.

A new San Diego-based startup called Nervana Systems wants to make deep learning more accessible by developing custom hardware built to process all that data.

To design the hardware, it has collected a seed round of $600,000 in funding from a group of Silicon Valley investors who are primarily associated with Internet companies, not chips. They are Ali and Hadi Partovi, Sam Altman, Geoff Ralston, Scott Banister, Owen Van Natta, Eric Baker, Farzad Khosrowshahi, Dara Khosrowshahi, Allen & Company, Aditya Agarwal and Ruchi Sanghvi, and SV Angel.

Nervana CEO Naveen Rao said that should be enough money for the company’s small team — which previously worked at Qualcomm and only started Nervana in March — to create a demo version.

It’s too far out to nail things down, but the product should be priced in the tens of thousands of dollars, Rao said.

“We’re running out of juice already when it comes to silicon,” Rao said. “Silicon has hit a wall. The only way to do it better is novel architectures.”

Here’s how Rao described Nervana’s solution: Deep learning is generally conducted on graphic processing units (GPUs) rather than general-purpose central processing units (CPUs) because GPUs are designed to handle parallel processes. But since data structures live in the memory, they tend to be moved back and forth as they are processed. That generates a lot of overhead. Nervana’s solution moves things back and forth less, because the state of the algorithm resides on the chip, rather than in the memory.

The real opportunity of Nervana is that by making deep learning more accessible, it will hopefully help researchers and companies make more interesting breakthroughs in artificial intelligence, said Ali Partovi, who helped assemble the investor group. Partovi and his brother Hadi knew about Nervana early on because CTO Amir Khosrowshahi is their cousin.

As Ali Partovi put it, today’s deep learning breakthroughs have been in things like computers training themselves to recognize cats in videos and make fewer speech recognition errors — things a human 4-year-old could easily do.

What would be more impressive to laypeople might be breakthroughs in areas like processing weather data, satellite photos and surveillance video — things people have more trouble doing with their own brains.



http://fastml.com/deep-learning-these-days/
==========================================================================
http://fastml.com/deep-learning-these-days/

But it is not so clear that ReLU + Dropout  really are better ... see this

http://www.reddit.com/r/MachineLearning/comments/22u1yt/is_deep_learning_basically_just_neural_networks/cgqgy9w




SciDB - if we ever need a DB for R (should datasets not fit into memory anymore)
==========================================================================
if we ever need a DB for R (should datasets not fit into memory anymore), then forget about Hadoop and all the other fancy names supposedly BigData... use SciDB.  It was made for R and integrates nicely and apparently makes complex computations (correlation, etc.) possible without having to copy data back and forth from DB to R.

Article:
 http://www.datanami.com/datanami/2014-04-09/array_databases:_the_next_big_thing_in_data_analytics_.html

Download:
 http://www.scidb.org/forum/viewtopic.php?f=16&t=364/

R package for SciDB (nice integration)
 https://github.com/Paradigm4/SciDBR

 




Finding relationships between assets that can be used for statistical arbitrage
==========================================================================
Instead of focusing on predicting price direction and price volatility with nonlinear models derived with machine learning methods, an alternative would be to try and discover exploitable price relationships between assets of the same class and react (=trade) when mispricing happens, in other words, do statistical arbitrage. In a sense this is somehow 'easier' than attempting to forecast prices, since the only thing one has to do is to find a relatively stable, linear or non-linear relationship between a group of at least two assets and assume that, from the time of its detection, that relationship will carry on for some time into the future. Trading under this assumption is then very much a reactive process that is triggered by price movements that diverge significantly from the modeled relationship. Traditional Pair Trading and trading of assetts in a VECM (Vector Error Correction Model) relationship are good examples for statarb using linear models. So why not use a simple one-layer neural network or even an RBM to discover a non-linear price relationship between two not-cointegrated assets and if this discovery process is successful, trade it in a similar way to a classical pair ? Things become even more interesting when groups with more than just two assets are considered. This would then be the non-linear equivalent of a VECM.




statarb and machine learning
==========================================================================
statarb basics:  We don't try to predict anything. We react to significant mispricing.

 

# let Xt be a stationary mean-reverting process, e.g. the residuals
 # between an index (ETF) and a *combination of the underlying stocks*.
 # i.e. We already have successfully tested Xt with the Advanced Dickey-Fuller test!
 # Machine learning techniques, such as clustering, could be used to find an appropriate # *combination of the underlying stocks* so that the residuals are indeed reverting.

#Xt <- runif(101)
 Xt <- (runif(200)+0.7)*sin(pi/10*1:200)

# check mean-reversion: need p.value < 0.01
 require(tseries)
 adf.test(as.numeric(Xt))

# fit an ar(1) model to get a and b
 fit <- arima(Xt,c(1,0,0))

a <- fit$coef['intercept']
 b <- fit$coef['ar1']

# Now get the Ornstein-Uhlenbeck params for the MR process from a and b
 delta.t <- 1/length(as.numeric(Xt))  #number of datapoints
 kappa.ou <-  -log(b)/delta.t
 m.ou     <- a/(1-b)
 sigma.ou <- sqrt( var(fit$residuals)*2*kappa.ou / (1-b*b) )
 sigmaeq.ou <- sqrt( var(fit$residuals) / (1-b*b) )

# now define signal

signal <- (Xt - m.ou) / sigmaeq.ou

# signal < -1.25 : buy ETF
 # signal > -0.5  : close long position ETF

# signal > 1.25 : sell ETF
 # signal < 0.5  : close short position ETF

###############################
 Or more in general:  Discover target assetts for statarb by using directed graphs where edges represent information transfer (either granger or transfer entropy) between assets. F
