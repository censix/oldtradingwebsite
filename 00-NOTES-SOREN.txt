XXXXXXXXXXXXXX
==========================================================================


XXXXXXXXXXXXXX
==========================================================================


XXXXXXXXXXXXXX
==========================================================================


mindboggingly simple gap trading strategy - maybe run a backtest sometime
==========================================================================
■Consider a list of 100 securities (the Nasdaq 100, I think)
■Using a 30-day trailing window, compute the difference (gap) between the daily opening price and the prior daily closing price
■Normalize the gap using a z-score
■Each day, identify the pair of stocks corresponding to the min and max gap z-scores
■Buy the stock with the min gap z-score, and short the stock with the max gap z-score
■After 3 pm, close open positions

https://www.quantopian.com/posts/market-closed-gap-trade



Using foreign C libraries (without compilation) in R
==========================================================================

http://cran.r-project.org/web/packages/rdyncall/index.html

No compilation is required, just the .so file has to be provided, but calling functions and passing arguments becomes painful .....






Read numpy data into R (binary)
==========================================================================
http://dirk.eddelbuettel.com/blog/2012/06/30/

# Create demo numpy  data:
#!/usr/bin/env python
#
# simple example for creating numpy data to demonstrate converter

import numpy as np

# simple float array
a = np.arange(15).reshape(3,5) * 1.1

outfile = "/tmp/data.npy"
np.save(outfile, a)
# use python to write special .bin file
#!/usr/bin/python
#
# read a numpy file, and write a simple binary file containing
#   two integers 'n' and 'k' for rows and columns
#   n times k floats with the actual matrix
# which can be read by any application or language that can read binary

import struct
import numpy as np

inputfile = "/tmp/data.npy"
outputfile = "/tmp/data.bin"

# load from the file
mat = np.load(inputfile)

# create a binary file
binfile = file(outputfile, 'wb')
# and write out two integers with the row and column dimension
header = struct.pack('2I', mat.shape[0], mat.shape[1])
binfile.write(header)
# then loop over columns and write each
for i in range(mat.shape[1]):
    data = struct.pack('%id' % mat.shape[0], *mat[:,i])
    binfile.write(data)
binfile.close()
# Read it into R !
#!/usr/bin/r

infile <- "/tmp/data.bin"
con <- file(infile, "rb")
dim <- readBin(con, "integer", 2)
Mat <- matrix( readBin(con, "numeric", prod(dim)), dim[1], dim[2])
close(con)

print(Mat)





DAX Liquidity Shock 7 feb 2014 - zwischen 14:25 und 14:45 ??
==========================================================================
DAX Liquidity Shock 7 feb 2014 - zwischen 14:25 und 14:45 ??

von 9270 auf 9230 und zurueck auf 9260 ....




Stacked Denoising Autoencoders - Implementation for Theano
==========================================================================
 
http://deeplearning.net/tutorial/SdA.html

Critical metaparameters to tune = number of autoencoders per layer and number of layers !!!

Theano code:
 http://deeplearning.net/tutorial/code/SdA.py

Or better: use pylearn2 (built on theano)

https://github.com/lisa-lab/pylearn2

look at
 pylearn2 / pylearn2 / models / autoencoder.py
 for implementation of stacked denoising autoencoders.





Amazing R tools from Duncan Temple Lang (RCUDA, RLLVM, ... RDropbox)
==========================================================================
The Father of http://omegahat.org has a git repository ....

https://github.com/duncantl?tab=repositories





rPython installation - purpose - use Theano (deeplearning) from R
==========================================================================
install rPython from CRAN
 =====================
 install.packages('rPython')
 # from R do

require(rPython)
 python.load('checkGPUuse.py')
 #works !!!
 #python.get('vlen')

# NOT SO GOOD :((  some python objects may not be JSON serializable and cannot be returned to
 # R, which ones ? what would the R  list() in python be ?

 

######## checkGPUuse.py
from theano import function, config, shared, sandbox
import theano.tensor as T
import numpy
import time

vlen = 10 * 30 * 768  # 10 x #cores x # threads per core
iters = 1000

rng = numpy.random.RandomState(22)
x = shared(numpy.asarray(rng.rand(vlen), config.floatX))
f = function([], T.exp(x))
print f.maker.fgraph.toposort()
t0 = time.time()
for i in xrange(iters):
    r = f()
t1 = time.time()
print 'Looping %d times took' % iters, t1 - t0, 'seconds'
print 'Result is', r
if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):
    print 'Used the cpu'
else:
    print 'Used the gpu'
    
    


pairs (classic): raw prices + adf test
==========================================================================
require(quantmod)
 A <- getSymbols('GLD',auto.assign=FALSE)
 B <- getSymbols('GDX',auto.assign=FALSE)
 #C <- getSymbols('AAPL',auto.assign=FALSE)

##################################################
 ############### CLASSIC ###################################
 ##################################################

# beta: price
 al <- Ad(A)
 bl <- Ad(B)
 colnames(al) <- 'A'
 colnames(bl) <- 'B'
 require(MASS)
 beta.calc <- rollapply(data=cbind(al,bl),width=40,by=1,by.column = FALSE,
 function(z){
 #c(nrow(z),ncol(z))
 fit <- rlm(A~B+0,data=as.data.frame(z))
 as.numeric(fit$coef)
 }, align = "right")

plot(beta.calc)

# mr.test.adf
 require(tseries)
 al <- Ad(A)
 bl <- Ad(B)
 test.in <- na.omit(cbind(beta.calc,al,bl))
 colnames(test.in) <- c('beta','A','B')
 mr.test.adf <- rollapply(data=test.in,width=40,by=1,by.column = FALSE,
 function(z){
 #return(c(nrow(z),ncol(z)))
 #return(as.numeric(c(last(z$A),last(z$beta),last(z$B))))
 spread <- as.data.frame(z$A - z$beta*z$B)
 #as.numeric(last(spread))
 tt <- adf.test(x=spread$A, alternative = "stationary", k=0)
 as.numeric(tt$p.value)
 }, align = "right")

plot(mr.test.adf)
 # percentage of days where the spread is mr with <0.05 significance
 sum(mr.test.adf<0.05,na.rm=TRUE)/nrow(mr.test.adf)

# PENDING. how long will a fitted model (spread) stay valid with the
 # same parameters. or in other words, how often do we have to refit ?

 

#~ # inspired by
 #~ # http://epchan.blogspot.ch/2013/11/cointegration-trading-with-log-prices.html
 #~ require(quantmod)
 #~ A <- getSymbols('YHOO',auto.assign=FALSE)
 #~ B <- getSymbols('GOOG',auto.assign=FALSE)
 #~ C <- getSymbols('AAPL',auto.assign=FALSE)
 #~
 #~
 #~ # mr.test.simple http://epchan.blogspot.ch/2013/11/cointegration-trading-with-log-prices.html
 #~ a<-diff(log(Ad(A)))
 #~ b<-diff(log(Ad(B)))
 #~ #varA <- runVar(a,n=20)
 #~ #varB <- runVar(b,n=20)
 #~ #covAB <- runCov(a,b,n=20)
 #~ mr.test.simple <- rollapply(data=cbind(a,b),width=20,by=1,by.column = FALSE,
 #~ function(z){
 #~     #c(nrow(z),ncol(z))
 #~     cov.mat <- cov(z)
 #~     #as.numeric(cov.mat[1,2])
 #~     as.numeric(mean(diag(cov.mat))-cov.mat[1,2]) # want this to be zero
 #~ }, align = "right")
 #~
 #~
 #~ # beta: log price
 #~ al <- log(Ad(A))
 #~ bl <- log(Ad(B))
 #~ colnames(al) <- 'A'
 #~ colnames(bl) <- 'B'
 #~ require(MASS)
 #~ beta.calc <- rollapply(data=cbind(al,bl),width=20,by=1,by.column = FALSE,
 #~ function(z){
 #~     #c(nrow(z),ncol(z))
 #~     fit <- rlm(A~B+0,data=as.data.frame(z))
 #~     as.numeric(fit$coef)
 #~ }, align = "right")
 #~

 

############### original below ##########

library(tseries) #for adf.test
 require(quantmod)

getSymbols('GLD')
 getSymbols('GDX')

gld <- Ad(GLD)
 gdx <- Ad(GDX)

t.zoo <- merge(gld, gdx, all=FALSE)
 t <- as.data.frame(t.zoo)
 colnames(t) <- c('GLD','GDX')

cat("Date range is", format(start(t.zoo)), "to", format(end(t.zoo)), "n")

m <- lm(GLD ~ GDX + 0, data=t)
 beta <- coef(m)[1]

cat("Assumed hedge ratio is", beta, "n")

sprd <- t$GLD - beta*t$GDX
 ht <- adf.test(sprd, alternative="stationary", k=0) #important. sprd has no timeseries format!!

cat("ADF p-value is", ht$p.value, "n")

# expect p-value = 0.1957. not coint

if (ht$p.value < 0.05) {
 cat("The spread is likely mean-revertingn")
 } else {
 cat("The spread is not mean-reverting.n")
 }






This is a trading competition with an emphasis on the machine learning aspect
==========================================================================
Read and look at the data (irregular 2sec timestamps, stock)

http://www
